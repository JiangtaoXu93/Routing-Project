---
title: "A5 - Routing"
author: "Jiangtao, Joyal and Bhanu"
date: "October 12, 2017"
output:
  html_document:
    fig_caption: yes
    toc: yes
  pdf_document:
    fig_caption: yes
    toc: yes
---

```{r setup, include=FALSE,echo=FALSE,results='hide',message=FALSE, warning=FALSE, cache=TRUE}
knitr::opts_chunk$set(echo = FALSE, cache=TRUE, warning = FALSE)
# install.packages('e1071', dependencies=TRUE)
library(ggplot2)
library(gridExtra)
library(dplyr)
library(magrittr)
library(ggplot2)
library(scales)
library(knitr)
library(data.table)
library(kableExtra)
library(randomForest)
library(caret)
knitr::opts_knit$set(root.dir = normalizePath(getwd()))
```

\newpage

# Problem
http://janvitek.org/pdpmr/f17/task-a5-routes.html

# Solution

## Architecture

*Arrows head represent the data flow*

## 1. RouteComputeJob
The job takes as `input` the airline dataset from year 1987-2015 and `query` file and outputs three files namely `test.csv`,`train.csv` and `validate.csv`. Each of the file serves purposes as shown below:

```{r, echo = FALSE,message=FALSE, warning=FALSE, cache=T}
fileDescDF <- read.csv("data/fileDesc.csv")
kable_styling(kable(fileDescDF,"html"), bootstrap_options = "striped", full_width = F)
```


### 1a. RouteComputeMapper

The mapper has the following instance members:

```{r, echo = FALSE,message=FALSE, warning=FALSE, cache=T}
mapperVarDF <- read.csv("data/mapperVarDF.csv")
kable_styling(kable(mapperVarDF,"html"),bootstrap_options = "striped", full_width = F)
```

#### Setup Phase
Each mapper will have shared access to `queryList` instance member described above. In setup phase, the `queryList` is populated with each row tuple from input query file.
Apart from this, the sdMap (source-destination map) and dsMap also gets populated. This is done as shown below:

Assume that for a given query file we have following values:

```{r, echo = FALSE,message=FALSE, warning=FALSE, cache=T}
sampleQueryDF <- read.csv("data/sampleQuery.csv")
kable_styling(kable(sampleQueryDF,"html"), bootstrap_options = "striped", full_width = T)
```        


As shown in the above table, there are two unique source (`BOS` and `ATL`) and four unique destination for query (`SEA`,`ATL`,`JFK`,`FLO`).

The sdMap will be populated with following key,value pairs

```{r, echo = FALSE,message=FALSE, warning=FALSE, cache=T}
sdMap <- read.csv("data/sdMap.csv")
kable_styling(kable(sdMap,"html"), bootstrap_options = "striped", full_width = F, position = "left")
```

The dsMap will be populated with following key,value pairs
```{r, echo = FALSE,message=FALSE, warning=FALSE, cache=T}
dsMap <- read.csv("data/dsMap.csv")
kable_styling(kable(dsMap,"html"), bootstrap_options = "striped", full_width = F, position = "left")
```

The main purpose of this job is to figure out a hop between source and destination. 

The below procedure shows exactly how each map will be used to figure out a route.

1. With the given query data, assume that in input we get a connection 'C' from 'BOS'.

2. For each input we will check whether the source matches any of the key for sdMap. 
   For example if the input has `BOS` as source then, according to map as `BOS` has 3 unique destinations, 
   for each input, map will emit three set of keys:
   
    ```
    <BOS-C-SEA>
    <BOS-C-ATL>
    <BOS-C-JFK>
    ```
   
    The value for each of these keys will have a flag set to '1', indicating this is a route for **Leg 1**.
    **C** is the current input data's destination value.

3. For each input we will also check whether the destination matches any of the key for dsMap. 
   For example if the input has `SEA` has destination then, according to map as `SEA` has one unique source,
   map will emit following keys:
   
    ```
    <BOS-C-SEA>
    ```
    
    The value for each of these keys will have a flag set to '2', indicating this is a route for **Leg 2**.
    **C** is the current input data's source value.

4. In the reducer, we will then have a key and list of values where the values will be either of leg1 or leg2 for that route.

#### Mapper Phase 

The mapper reads each line from flight record csv file, cleans data as per given sanity rules and emits 2 kind of <key,value> pair. Given a year, it emits test data in that year
and train data **not** in that year. The `key` is type of `RouteKey` class which implements `WritableComparable` interface while the `value` is type of `FlightData` class which implements `Writable` interface.

```
# RouteComputeMapper Input k,v
LongWritable, Text
# RouteComputeMapper Output k,v
RouteKey, FlightData
```

#### RouteKey
    
The structure of `RouteKey` is as shown below:
      
```java
public class RouteKey implements WritableComparable<RouteKey> {
  private Text source;
  private Text hop;
  private Text destination;
  private IntWritable type;//1-Train;2-Test
  private Text date;//yyyyMMdd
}
```

The mapper emits key of type `RouteKey` for both train and test dataset.

The following are the differences between the implementation of mapper for train and test data.

1. For train dataset the value for type would be **1**, while for test dataset the value for the type would be **2**.

2. For **train** dataset, mapper emits leg1 and leg2 flight for a user configured value which is less than query year value.
   For example, if the query year is `2001` and the user has specified `3` years for model generation, then the train dataset will contain
   data for years **`{1998,1999,2000}`**.
   
   For **test** dataset, mapper emits leg1 and leg2 flight for query year value. So, in the above example, the test dataset will contain
   data for year **`2001`** only.
   
3. There is one more implementation in the test phase. Suppose, for a given route A-C-B, where A is the source, C is the hop and B is the destination, if the    flight reaches C at 2330 hours for a given date, and the next flight from C to B is at 0030 for the next date, then below condition is specifically 
   handled in the code.
   
   
```java
String queryNextDate = getNextDate(queryDate);
 
if (StringUtils.equals(queryNextDate, flightDate)) {//if arrive at destination next day
    //Emit Test LegTwo
    if (StringUtils.equals(queryDes, fd.getDest().toString())) {
      fd.setLegType(new IntWritable(2));
      RouteKey rk = new RouteKey(new Text(queryOrigin), fd.getOrigin(), fd.getDest(),
          new IntWritable(2), new Text(queryDate));
      context.write(rk, fd);
    }
}
```
   
   Here, for test data a new set of <key, value> pair will be emitted where the key will have date for next day. 

#### FlightData

The structure of `FlightData` is as shown below:

```java
public class FlightData implements Writable {
  public static final String SEP_COMMA = ",";
  /**
   * LegType is the flight type in one complete route.
   * If the route is A->C->B
   * LegType=1 -> Flight A-C
   * LegType=2 -> Flight C-B
   */
  private IntWritable legType;
  private IntWritable year;//YEAR
  private IntWritable month;//MONTH
  private IntWritable dayOfWeek;//DAY_OFF_WEEK
  private IntWritable dayOfMonth;//DAY_OF_MONTH
  private IntWritable hourOfDay;//Computed from
  private IntWritable flightId;//FL_NUM
  private Text carrier;//UNIQUE_CARRIER
  private Text origin;//ORIGIN
  private Text dest;//DEST
  private Text schDepTime;//CRS_DEP_TIME (local time: hhmm)
  private Text actDepTime;//DEP_TIME (local time: hhmm)
  private Text schArrTime;//CRS_ARR_TIME (local time: hhmm)
  private Text actArrTime;//ARR_TIME (local time: hhmm)
  private FloatWritable arrDelay;//NORMALISED_DELAY
  private FloatWritable depDelay;//NORMALISED_DELAY
  private Text schElapsedTime;//CRS_ELAPSED_TIME (hhmm)
  private Text actElapsedTime;//ELAPSED_TIME (hhmm)
  private BooleanWritable cancelled;////CANCELLED
}
```
This class has its own getter and setter methods and stores value of each input csv record. There is also a special field `legType`, which takes either of
two values: **`1`** or **`2`**, where **`1`** indicates flight data for **Leg1** journey and **`2`** indicates flight data for **Leg2** journey.

### 1b. RouteComputeReducer

The Reducer phase receives input and emits output in the following `<k,v>` format

```
# RouteComputeReducer Input k,v
RouteKey, FlightData
# RouteComputeReducer Output k,v
RouteKey, RouteData
```

The reducer generates the training and testing data set and its implementation differs in the followings for both datasets.

```
 For Train
 Input:
  - Key: <RouteKey> With RouteKey.type = 1
  - Iterator<FlightData>:  All LegOne and LegTwo Flights for given Key
 
 Output: Emits every two hop route for the given key in the following format,
  - Key : <RouteKey>
  - Value: <RouteData> With RouteData.isValid as label, depending upon actual layover time at the hop.
  (This label is used to train the model)
```

```
 For Test
 Input:
  - Key: <RouteKey> With RouteKey.type = 2
  - Iterator<FlightData>:  All LegOne and LegTwo Flights for given Key
 
 Output: Emits every two hop route for the given key in the following format,
  - Key : <RouteKey>
  - Value: <RouteData> With RouteData.isValid as label, depending upon actual layover time at the hop.
  (This label is only used to validate the predictions from the model)
```

# Prediction

After generating test/train data through the MR job we use KNN classifier to predict labels for the test routes. (Please note that label=1 is an invalid route and label=2 is a valid route.)

```{r, warning=FALSE, cache=TRUE, echo=FALSE} 
#Load Data
set.seed(3333)
cols <- c("dataType","origin","hop","des","flightDate","l1.flightType","l1.year","l1.month","l1.dayOfWeek","l1.dayOfMonth","l1.hourOfDay","l1.flightId","l1.carrier","l1.origin","l1.dest","l1.schDepTime","l1.actDepTime","l1.schArrTime","l1.actArrTime","l1.arrDelay","l1.depDelay","l1.schElapsedTime","l1.actElapsedTime","l1.cancelled","l2.flightType","l2.year","l2.month","l2.dayOfWeek","l2.dayOfMonth","l2.hourOfDay","l2.flightId","l2.carrier","l2.origin","l2.dest","l2.schDepTime","l2.actDepTime","l2.schArrTime","l2.actArrTime","l2.arrDelay","l2.depDelay","l2.schElapsedTime","l2.actElapsedTime","l2.cancelled","label")

train.data <- fread(file="data/train-r-00000",header=F,stringsAsFactors=TRUE, col.names = cols)
test.data <- fread(file="data/test-r-00000",header=F,stringsAsFactors=TRUE, col.names = cols)

# train.data <- fread(file="../output/route/train-r-00000",header=F,stringsAsFactors=TRUE, col.names = cols)
# test.data <- fread(file="../output/route/test-r-00000",header=F,stringsAsFactors=TRUE, col.names = cols)

# Feature List 
# model.feature.list <- c("dataType", "l1.month","l1.dayOfWeek","l1.dayOfMonth","l1.hourOfDay","l1.carrier","l1.dest","l2.month","l2.dayOfWeek","l2.dayOfMonth","l2.hourOfDay","l2.carrier","l2.origin","label")

model.feature.list <- c("l1.month","l1.dayOfWeek","l1.dayOfMonth","l1.hourOfDay","l2.month","l2.dayOfWeek","l2.dayOfMonth","l2.hourOfDay","label")


# Feature Selection on Test and Train
model.train.data <- train.data[, model.feature.list, with=FALSE]
model.test.data <-  test.data[, model.feature.list, with=FALSE]

# Converting column `label` from Integer to Factor. This is required to run a classifier.  
model.train.data[,"label"] <-lapply(model.train.data[, "label", with=FALSE], factor)

# Extracting and removing labels(0) from test set.
model.test.label.actual <- model.test.data[,"label"] 
model.test.label.actual <- as.numeric(model.test.label.actual$label)
model.test.data[, "label":=NULL]

# Sampling Test Data to Random 10000 rows
model.train.data<-model.train.data[sample(nrow(model.train.data), 10000),]
```

## Train Data Set
The complete train dataset contains 23K observations, but due to compute bottleneck in R, we randomly sampled training data to 10,000. Thus there are 10,000 rows, 8 features, and 1 label. 
```{r, warning=FALSE, cache=TRUE} 
dim(model.train.data)
```
Below are the features we selected for the model. These features basically predict on the seasonal delay trend.
```{r, warning=FALSE, cache=TRUE} 
str(model.train.data)
```

## Test Data Set
Training set has 877 observations distributed over 8 similar features. These are all the possible two hop routes for the given input query.
```{r, warning=FALSE, cache=TRUE} 
dim(model.test.data)
```
```{r, warning=FALSE, cache=TRUE} 
str(model.test.data)
```
## KNN Classifier
While training a classifier we are using repeated cross validation to optimize the model parameters such as k(no of neighbors). Additionally there is a data normalization and scaling for features before feeding to the classifier.
```{r, warning=FALSE, cache=TRUE} 
# Model
trctrl <- trainControl(method = "repeatedcv", number = 10, repeats = 3)
model.knn <- train(label~., data = model.train.data, method = "knn"
 ,trControl=trctrl
 ,preProcess = c("center", "scale")
 ,tuneLength = 10
 )
model.knn
```


```{r, warning=FALSE, cache=TRUE} 
plot(model.knn,main = "Plot1. KNN Neighbors vs Accuracy")
```

`Plot 1.` shows accuracy per k. With parameter optimization we found the that `k=7` is giving best accuracy of  `0.8857669`.


```{r, warning=FALSE, cache=TRUE,echo=FALSE} 
model.test.label.predictions <- predict(model.knn, newdata=model.test.data)
model.test.label.predictions <-as.numeric(model.test.label.predictions)
model.test.cf <- confusionMatrix(model.test.label.predictions, model.test.label.actual)
model.test.recall <- recall(factor(model.test.label.predictions), factor(model.test.label.actual))
model.test.precision <- precision(factor(model.test.label.predictions), factor(model.test.label.actual))
```

## Confusion Matrix
```{r, warning=FALSE, cache=TRUE} 
model.test.cf
fourfoldplot(model.test.cf$table, main = "Plot 2. Confusion Matrix for Acutal vs Predictions ")
```

`Plot 2.` is a confusion matrix, that gives direct comparison between our prediction labels and actual test labels. 

* The Quadrant-1 = 59  -> We labelled 59 routes as 1(not valid) while they were actually 2(valid).
* The Quadrant-2 = 611 -> We labelled 611 routes as 1(not valid) while they were actually 1(valid).
* The Quadrant-3 = 125 -> We labelled 125 routes as 2(valid) while they were actually 1(not valid).
* The Quadrant-4 = 82  -> We labelled 82 routes as 2(valid) while they were actually 2(valid).

Further, we get an accuracy of `0.7902` on our test data. This number is pretty decent and can improve with increasing the sample space and more intrinsic feature selection.

## Plot for KNN Labels
```{r, warning=FALSE, cache=TRUE} 
# p <- ggplot(classify.results.sample, aes(logpr.a, logpr.b))
# p + geom_point(aes(colour = factor(item.class))) + geom_abline(intercept=0, slope=1)

```

```{r, warning=FALSE, cache=TRUE, echo=FALSE}
# Scoring Final Valid Routes with label 2
route.data <- test.data
route.data$label <- model.test.label.predictions
routes.valid <- route.data[label==2]
score.total <- 0
score.total.count <- nrow(routes.valid)
score.delay.count <-0
score.nondelay.count <-0
for (x in 1:nrow(routes.valid)){
  if(routes.valid[x,"l1.arrDelay"]>0 || routes.valid[x,"l2.arrDelay"]>0){
    score.total<-score.total-100
    score.delay.count<-score.delay.count+1
  }else{
    score.total<-score.total+1
    score.nondelay.count=score.nondelay.count+1
  }
}
final.score<-data.frame(score.total,score.total.count,score.delay.count,score.nondelay.count)
colnames(final.score)<-c("Score","Total Valid Route Count","Delay Route Count","NonDelay Route Count")
output.routes <- routes.valid[,c("flightDate","origin","des","l1.actDepTime","l1.actArrTime","l1.carrier","l1.origin","l1.dest","l2.actDepTime","l2.actArrTime","l2.carrier","l2.origin","l2.dest")]
```

# Results

## Input Queries
```{r, warning=FALSE, cache=TRUE, echo=F, message=FALSE} 
kable(read.csv("../query/query.csv",header=F, col.names = c("year","month","day","origin","destination"))) %>% kable_styling(bootstrap_options = "striped", full_width = F)
```

## Ouput Routes 
```{r, warning=FALSE, cache=TRUE, echo=F, message=FALSE} 
kable(output.routes) %>% kable_styling(bootstrap_options = "striped", full_width = F)
write.csv(output.routes, file = "finalOutputRoutes.csv",row.names=FALSE)
```

## Scores
```{r, warning=FALSE, cache=TRUE, message=F, echo=F}
kable(t(final.score)) %>% kable_styling(bootstrap_options = "striped", full_width = F)
```


# Job Execution


## Psuedo Distributed 

Used the below machine, to run the job in Pseudo Distributed mode.
```
OS: OSX
Processor Name:	Intel Core i7
Processor Speed:	2.8 GHz
Number of Processors:	1
Total Number of Cores:	4
L2 Cache (per Core):	256 KB
L3 Cache:	6 MB
Memory:	16 GB 
SSD: 256 GB

```

The job took 14.5m to run on the complete corpus. Below are some important observations, 

* Input of 6.55 GB(for 337 items) was reduced to train-data(41.6 MB) and test-data(158.6 KB)
* Total input files to process : 337 and Number of splits:337. Per file per mapper which is expected default behavior.  

## AWS EMR
Ran the same job on 4 cluster m4.xlarge EMR. The entire corpus took 10.4m to run. There is not much improvement because the data not big enough to produce any noticeable results. Also there is network i/o between distributed mappers and reducer causing some delay.